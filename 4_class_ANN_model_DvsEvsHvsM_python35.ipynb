{"nbformat_minor": 1, "cells": [{"source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='0173f8a1-9364-4a93-85fd-5a49de9c53f1', project_access_token='p-8c8d4ebd62e185973357f8daf6fe46662979370c')\npc = project.project_context", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 1}, {"source": "# 1. Set up the environment\n\nBefore running the code in this notebook, please make sure you have the following requirements:\n\nA Watson Machine Learning (WML) Service instance (a free plan is offered and information about how to create an instance can be found here)\n\n1. Local python environment configurations:\n- Python 3.5\n- watson-machine-learning-client\n- pixiedust\n- matplotlib\n- seaborn\n- keras\n\n2. Download the Grape leaves dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "# 2. Load and explore the data\n\nIn this section, we will load the data into a pandas dataframe and perform an exploratory data analysis (EDA).\n", "cell_type": "markdown", "metadata": {}}, {"source": "!rm -Rf datasetWS_DvsEvsHvsM_512-512_git", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 2}, {"source": "!git clone https://github.com/RenataUjhaziova/datasetWS_DvsEvsHvsM_512-512_git.git", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Cloning into 'datasetWS_DvsEvsHvsM_512-512_git'...\nremote: Enumerating objects: 292, done.\u001b[K\nremote: Counting objects: 100% (292/292), done.\u001b[K\nremote: Compressing objects: 100% (290/290), done.\u001b[K\nremote: Total 292 (delta 0), reused 289 (delta 0), pack-reused 0\u001b[K\nReceiving objects: 100% (292/292), 49.26 MiB | 39.68 MiB/s, done.\n"}], "execution_count": 3}, {"source": "!ls", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "4_class_ANN_cv_model_DvsEvsHvsM_v1_weights.h5\r\n4_class_ANN_model_DvsEvsHvsM_v1_weights.h5\r\nclass_4_ANN_cv_model_DvsEvsHvsM_v1.h5\r\nclass_4_ANN_cv_model_DvsEvsHvsM_v1_weights.h5\r\nclass_4_ANN_model_DvsEvsHvsM_v1-1.h5\r\nclass_4_ANN_model_DvsEvsHvsM_v1-1_weights.h5\r\nclass_4_ANN_model_DvsEvsHvsM_v1.h5\r\ndatasetWS_DvsEvsHvsM_512-512_git\r\n"}], "execution_count": 4}, {"source": "%cd ./datasetWS_DvsEvsHvsM_512-512_git/", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "/home/dsxuser/work/datasetWS_DvsEvsHvsM_512-512_git\n"}], "execution_count": 5}, {"source": "!pip install opencv-python ", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Requirement already satisfied: opencv-python in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (4.1.0.25)\nRequirement already satisfied: numpy>=1.11.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from opencv-python) (1.13.3)\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n"}], "execution_count": 6}, {"source": "# Get the data.\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 7}, {"source": "# read images\ndef read_images(path):\n    print('Reading from', path)\n    files = [file for file in os.listdir(path)]\n    image = cv2.imread(path+files[0])\n    images = np.zeros(shape=(len(files), 512, 512, image.shape[2]))\n    for i in range(len(files)):\n        image = cv2.imread(path+files[i])\n        images[i,:,:,:] = cv2.resize(image,(512,512))\n    return images", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 8}, {"source": "healthy_train = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/training_set/healthy/')\nesca_train = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/training_set/esca/')\ndry_train = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/training_set/dry/')\nmite_train = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/training_set/mite/')", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Reading from ../datasetWS_DvsEvsHvsM_512-512_git/training_set/healthy/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/training_set/esca/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/training_set/dry/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/training_set/mite/\n"}], "execution_count": 9}, {"source": "healthy_test = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/test_set/healthy/')\nesca_test = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/test_set/esca/')\ndry_test = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/test_set/dry/')\nmite_test = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/test_set/mite/')", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Reading from ../datasetWS_DvsEvsHvsM_512-512_git/test_set/healthy/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/test_set/esca/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/test_set/dry/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/test_set/mite/\n"}], "execution_count": 10}, {"source": "# record count in each classes\nplt.figure(0)\nplt.bar(['dry', 'esca', 'healthy', 'mite'],\\\n        [healthy_train.shape[0] + healthy_test.shape[0],\n         esca_train.shape[0] + esca_test.shape[0], \n         dry_train.shape[0] + dry_test.shape[0], \n         mite_train.shape[0] + mite_test.shape[0]])\nplt.show()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "display_data", "data": {"image/png": "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\n", "text/plain": "<matplotlib.figure.Figure at 0x7fee28166f98>"}, "metadata": {}}], "execution_count": 11}, {"source": "# create dataframe\nimport pandas as pd", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 12}, {"source": "data = pd.DataFrame(columns=['hist_data', 'label'])\ndef append_to_df(img_array, df, label):\n    for image in img_array:\n        hist_b = np.histogram(image[:,:,0], bins=30, density=True, range=(0,255))[0]\n        hist_g = np.histogram(image[:,:,1], bins=30, density=True, range=(0,255))[0]\n        hist_r = np.histogram(image[:,:,2], bins=30, density=True, range=(0,255))[0]\n        hist = np.append(np.append(hist_r, hist_g), hist_b)\n        df = df.append({'hist_data': hist, 'label': label}, ignore_index=True)\n    return df", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 13}, {"source": "data = append_to_df(dry_train, data,0)\ndata = append_to_df(dry_test, data,0)\ndata = append_to_df(esca_train, data,1)\ndata = append_to_df(esca_test, data,1)\ndata = append_to_df(healthy_train, data,2)\ndata = append_to_df(healthy_test, data,2)\ndata = append_to_df(mite_train, data,3)\ndata = append_to_df(mite_test, data,3)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 14}, {"source": "data.head(20)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hist_data</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[2.69272748162e-06, 1.07709099265e-05, 0.00014...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.0, 0.0, 2.87224264706e-05, 0.00014495849609...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[4.03909122243e-06, 9.42454618566e-06, 4.03909...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[8.97575827206e-06, 9.24503102022e-05, 0.00115...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[2.69272748162e-06, 3.63518210018e-05, 0.00055...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[4.48787913603e-07, 4.03909122243e-05, 0.00103...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[4.48787913603e-07, 3.14151539522e-06, 2.10930...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[4.48787913603e-06, 5.02642463235e-05, 0.00053...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[1.03221220129e-05, 6.82157628676e-05, 0.00048...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[3.14151539522e-06, 2.42345473346e-05, 0.00029...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[8.52697035846e-06, 1.97466681985e-05, 0.00014...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[0.0, 8.97575827206e-07, 1.16684857537e-05, 0....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[8.07818244485e-06, 3.41078814338e-05, 0.00015...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[1.84003044577e-05, 5.78936408548e-05, 0.00070...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[2.24393956801e-06, 4.62251551011e-05, 0.00016...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>[1.34636374081e-06, 1.07709099265e-05, 0.00010...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>[1.97466681985e-05, 4.62251551011e-05, 0.00070...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>[4.48787913603e-07, 4.12884880515e-05, 0.00093...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>[1.34636374081e-06, 8.07818244485e-06, 0.00068...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>[1.34636374081e-06, 1.07709099265e-05, 0.00069...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                            hist_data label\n0   [2.69272748162e-06, 1.07709099265e-05, 0.00014...     0\n1   [0.0, 0.0, 2.87224264706e-05, 0.00014495849609...     0\n2   [4.03909122243e-06, 9.42454618566e-06, 4.03909...     0\n3   [8.97575827206e-06, 9.24503102022e-05, 0.00115...     0\n4   [2.69272748162e-06, 3.63518210018e-05, 0.00055...     0\n5   [4.48787913603e-07, 4.03909122243e-05, 0.00103...     0\n6   [4.48787913603e-07, 3.14151539522e-06, 2.10930...     0\n7   [4.48787913603e-06, 5.02642463235e-05, 0.00053...     0\n8   [1.03221220129e-05, 6.82157628676e-05, 0.00048...     0\n9   [3.14151539522e-06, 2.42345473346e-05, 0.00029...     0\n10  [8.52697035846e-06, 1.97466681985e-05, 0.00014...     0\n11  [0.0, 8.97575827206e-07, 1.16684857537e-05, 0....     0\n12  [8.07818244485e-06, 3.41078814338e-05, 0.00015...     0\n13  [1.84003044577e-05, 5.78936408548e-05, 0.00070...     0\n14  [2.24393956801e-06, 4.62251551011e-05, 0.00016...     0\n15  [1.34636374081e-06, 1.07709099265e-05, 0.00010...     0\n16  [1.97466681985e-05, 4.62251551011e-05, 0.00070...     0\n17  [4.48787913603e-07, 4.12884880515e-05, 0.00093...     0\n18  [1.34636374081e-06, 8.07818244485e-06, 0.00068...     0\n19  [1.34636374081e-06, 1.07709099265e-05, 0.00069...     0"}, "execution_count": 15}], "execution_count": 15}, {"source": "# creating variables and labes\nX = np.stack(data['hist_data'].values)\ny = data['label'].values.astype(int)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 16}, {"source": "# splitting the dataset into the Training and Testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 0)\n\n# List the number of records in each data set.\nprint('Number of training records: ' + str(len(X_train)))\nprint('Number of testing records : ' + str(len(X_test)))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Number of training records: 186\nNumber of testing records : 62\n"}], "execution_count": 17}, {"source": "## 2.1 Prepare validation data", "cell_type": "markdown", "metadata": {}}, {"source": "healthy_val = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/validation_set/healthy/')\nesca_val = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/validation_set/esca/')\ndry_val = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/validation_set/dry/')\nmite_val = read_images(path= '../datasetWS_DvsEvsHvsM_512-512_git/validation_set/mite/')", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Reading from ../datasetWS_DvsEvsHvsM_512-512_git/validation_set/healthy/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/validation_set/esca/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/validation_set/dry/\nReading from ../datasetWS_DvsEvsHvsM_512-512_git/validation_set/mite/\n"}], "execution_count": 18}, {"source": "data_val = pd.DataFrame(columns=['hist_data', 'label'])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 19}, {"source": "data_val = append_to_df(dry_val, data_val,0)\ndata_val = append_to_df(esca_val, data_val,1)\ndata_val = append_to_df(healthy_val, data_val,2)\ndata_val = append_to_df(mite_val, data_val,3)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 20}, {"source": "# creating variables and labes\nX_val = np.stack(data_val['hist_data'].values)\ny_val = data_val['label'].values.astype(int)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 21}, {"source": "# 3. Build the Model", "cell_type": "markdown", "metadata": {}}, {"source": "# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\nX_val = sc.transform(X_val)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 22}, {"source": "# Importing the Keras libraries and packages\nimport keras", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}], "execution_count": 23}, {"source": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 24}, {"source": "# convert class vectors to binary class matrices\nnum_classes = 4\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\ny_val = keras.utils.to_categorical(y_val, num_classes)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 25}, {"source": "ANN_model = Sequential()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 26}, {"source": "# Adding the input layer and the first hidden layer\nANN_model.add(Dense(output_dim = 45, \n                    init = 'uniform', \n                    activation = 'relu', \n                    input_dim = 90))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=45, activation=\"relu\", input_dim=90, kernel_initializer=\"uniform\")`\n  from ipykernel import kernelapp as app\n"}], "execution_count": 27}, {"source": "# Adding the second hidden layer\nANN_model.add(Dense(output_dim = 45, \n                    init = 'uniform', \n                    activation = 'relu'))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=45, activation=\"relu\", kernel_initializer=\"uniform\")`\n  from ipykernel import kernelapp as app\n"}], "execution_count": 28}, {"source": "# Adding the output layer\nANN_model.add(Dense(output_dim = 4, \n                    init = 'uniform', \n                    activation = 'softmax'))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=4, activation=\"softmax\", kernel_initializer=\"uniform\")`\n  from ipykernel import kernelapp as app\n"}], "execution_count": 29}, {"source": "# Compiling the ANN\nANN_model.compile(optimizer = 'adam', \n                  loss = 'categorical_crossentropy', \n                  metrics = ['accuracy'])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 30}, {"source": "## 3.1 Train the model", "cell_type": "markdown", "metadata": {}}, {"source": "from IPython.display import clear_output", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 31}, {"source": "class PlotLearning(Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.acc = []\n        self.val_acc = []\n        self.fig = plt.figure()\n        \n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        self.i += 1\n        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n        \n        clear_output(wait=True)\n        \n        ax1.set_yscale('log')\n        ax1.plot(self.x, self.losses, label=\"loss\")\n        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n        ax1.legend()\n        \n        ax2.plot(self.x, self.acc, label=\"accuracy\")\n        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n        ax2.legend()\n        \n        plt.show();\n        \nplot_learning = PlotLearning()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 32}, {"source": "# Fitting the ANN to the Training set\nANN_model.fit(X_train, y_train, batch_size = 10, \n              nb_epoch = 30, \n              validation_data=(X_test, y_test), \n              callbacks=[plot_learning])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "display_data", "data": {"image/png": "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\n", "text/plain": "<matplotlib.figure.Figure at 0x7fec9053f358>"}, "metadata": {}}, {"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "<keras.callbacks.History at 0x7fee2a1685f8>"}, "execution_count": 33}], "execution_count": 33}, {"source": "### 3.2 Test the Model", "cell_type": "markdown", "metadata": {}}, {"source": "ANN_model_result_path = \"/home/dsxuser/work/datasetWS_DvsEvsHvsM_512-512_git/class_4_ANN_model_DvsEvsHvsM_v1-1.h5\"\nANN_model.save(ANN_model_result_path)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 34}, {"source": "ANN_model.save_weights('/home/dsxuser/work/datasetWS_DvsEvsHvsM_512-512_git/class_4_ANN_model_DvsEvsHvsM_v1-1_weights.h5')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 35}, {"source": "score_train = ANN_model.evaluate(X_train, y_train, verbose=0)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 36}, {"source": "print(\"Loss = \", score_train[0], \", Accuracy = \", score_train[1])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Loss =  0.0115081071052 , Accuracy =  1.0\n"}], "execution_count": 37}, {"source": "score_test = ANN_model.evaluate(X_test, y_test, verbose=0)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 38}, {"source": "print(\"Loss = \", score_test[0], \", Accuracy = \", score_test[1])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Loss =  0.718779088989 , Accuracy =  0.838709665883\n"}], "execution_count": 39}, {"source": "score_val = ANN_model.evaluate(X_val, y_val, verbose=0)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 40}, {"source": "print(\"Loss = \", score_val[0], \", Accuracy = \", score_val[1])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Loss =  0.589118480682 , Accuracy =  0.833333313465\n"}], "execution_count": 41}, {"source": "ANN_model.summary()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 45)                4095      \n_________________________________________________________________\ndense_2 (Dense)              (None, 45)                2070      \n_________________________________________________________________\ndense_3 (Dense)              (None, 4)                 184       \n=================================================================\nTotal params: 6,349\nTrainable params: 6,349\nNon-trainable params: 0\n_________________________________________________________________\n"}], "execution_count": 42}, {"source": "## 3.3 Accuracy Testing", "cell_type": "markdown", "metadata": {}}, {"source": "Accuracy testing of test dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "#predictions_test\npredictions_test = ANN_model.predict(X_test)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 43}, {"source": "y_pred_test =[]\nfor i in range(len(predictions_test)):\n    y_pred_test.append(np.argmax(predictions_test[i]))\nprint(y_pred_test)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[3, 2, 3, 2, 2, 1, 0, 2, 3, 1, 1, 1, 1, 3, 3, 3, 0, 1, 3, 1, 3, 1, 2, 1, 0, 3, 0, 1, 1, 3, 1, 0, 3, 1, 2, 0, 0, 2, 0, 2, 3, 2, 1, 2, 1, 2, 3, 2, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 2, 2, 1, 2]\n"}], "execution_count": 44}, {"source": "y_test", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.]])"}, "execution_count": 45}], "execution_count": 45}, {"source": "y_test_labels = [ np.where(r==1)[0][0] for r in y_test ]\ny_test_labels", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[3,\n 2,\n 1,\n 2,\n 2,\n 1,\n 0,\n 2,\n 3,\n 3,\n 1,\n 3,\n 1,\n 2,\n 2,\n 3,\n 0,\n 1,\n 3,\n 1,\n 3,\n 2,\n 2,\n 1,\n 0,\n 3,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 3,\n 1,\n 2,\n 0,\n 0,\n 2,\n 0,\n 2,\n 3,\n 3,\n 1,\n 2,\n 1,\n 2,\n 3,\n 2,\n 1,\n 3,\n 1,\n 0,\n 3,\n 0,\n 1,\n 0,\n 3,\n 2,\n 2,\n 2,\n 3,\n 2]"}, "execution_count": 46}], "execution_count": 46}, {"source": "ctr_test=0\nfor i in range(len(y_pred_test)):\n    if y_pred_test[i] == y_test_labels[i]:\n        ctr_test=ctr_test+1\nres_test = ctr_test/len(y_pred_test)*100\nprint(res_test)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "83.87096774193549\n"}], "execution_count": 47}, {"source": "Accuracy testing of validation data set.", "cell_type": "markdown", "metadata": {}}, {"source": "#predictions_test\npredictions_val = ANN_model.predict(X_val)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 48}, {"source": "y_pred_val =[]\nfor i in range(len(predictions_val)):\n    y_pred_val.append(np.argmax(predictions_val[i]))\nprint(y_pred_val)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2, 3, 1, 1, 3, 1, 3]\n"}], "execution_count": 49}, {"source": "y_val", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.]])"}, "execution_count": 50}], "execution_count": 50}, {"source": "y_val_labels = [ np.where(r==1)[0][0] for r in y_val ]\ny_val_labels", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]"}, "execution_count": 51}], "execution_count": 51}, {"source": "ctr_val=0\nfor i in range(len(y_pred_val)):\n    if y_pred_val[i] == y_val_labels[i]:\n        ctr_val=ctr_val+1\nres_val = ctr_val/len(y_pred_val)*100\nprint(res_val)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "83.33333333333334\n"}], "execution_count": 52}, {"source": "## 3.4 Confusion matrix", "cell_type": "markdown", "metadata": {}}, {"source": "Confusion matrix for test dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "from sklearn.metrics import confusion_matrix", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 53}, {"source": "# confusion matrix for test data\ny_actu_test = y_test_labels", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 54}, {"source": "y_pred_test = y_pred_test", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 55}, {"source": "!pip install pycm", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Requirement already satisfied: pycm in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (2.3)\nRequirement already satisfied: numpy>=1.9.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pycm) (1.13.3)\nRequirement already satisfied: art>=1.8 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pycm) (3.7)\nRequirement already satisfied: coverage>=4.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from art>=1.8->pycm) (4.5.3)\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n"}], "execution_count": 56}, {"source": "from pycm import *", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 57}, {"source": "Confusion matrix for test dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "cm_test = ConfusionMatrix(actual_vector=y_actu_test, predict_vector=y_pred_test) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 58}, {"source": "cm_test.classes", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[0, 1, 2, 3]"}, "execution_count": 59}], "execution_count": 59}, {"source": "cm_test.table", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "{0: {0: 11, 1: 0, 2: 0, 3: 0},\n 1: {0: 0, 1: 15, 2: 0, 3: 2},\n 2: {0: 0, 1: 1, 2: 14, 3: 3},\n 3: {0: 0, 1: 3, 2: 1, 3: 12}}"}, "execution_count": 60}], "execution_count": 60}, {"source": "cm_test.print_matrix()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Predict  0        1        2        3        \nActual\n0        11       0        0        0        \n\n1        0        15       0        2        \n\n2        0        1        14       3        \n\n3        0        3        1        12       \n\n\n"}], "execution_count": 61}, {"source": "Confusion matrix for validation dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "# confusion matrix for validation data\ny_actu_val = y_val_labels", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 62}, {"source": "# confusion matrix for validation data\ny_pred_val = y_pred_val", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 63}, {"source": "cm_val = ConfusionMatrix(actual_vector=y_actu_val, predict_vector=y_pred_val)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 64}, {"source": "cm_val.classes", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[0, 1, 2, 3]"}, "execution_count": 65}], "execution_count": 65}, {"source": "cm_val.table", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "{0: {0: 6, 1: 0, 2: 0, 3: 0},\n 1: {0: 0, 1: 6, 2: 0, 3: 0},\n 2: {0: 0, 1: 0, 2: 5, 3: 1},\n 3: {0: 0, 1: 3, 2: 0, 3: 3}}"}, "execution_count": 66}], "execution_count": 66}, {"source": "#print(cm_val)\ncm_val.print_matrix()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Predict 0       1       2       3       \nActual\n0       6       0       0       0       \n\n1       0       6       0       0       \n\n2       0       0       5       1       \n\n3       0       3       0       3       \n\n\n"}], "execution_count": 67}, {"source": "## 4. Build the Model using cross validation ", "cell_type": "markdown", "metadata": {}}, {"source": "## 4.1 Train the model", "cell_type": "markdown", "metadata": {}}, {"source": "from sklearn.model_selection import StratifiedKFold", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 68}, {"source": "seed = 7\nnp.random.seed(seed)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 69}, {"source": "kfold = StratifiedKFold(n_splits=10, shuffle=True, \n                        random_state=seed)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 70}, {"source": "for train, test in kfold.split(X, y):\n    cv_model = Sequential()\n    cv_model.add(Dense(output_dim = 45, \n                       init = 'uniform', \n                       activation = 'relu', \n                       input_dim = 90))\n    cv_model.add(Dense(output_dim = 45, \n                       init = 'uniform', \n                       activation = 'relu'))\n    cv_model.add(Dense(output_dim = 4, \n                       init = 'uniform', \n                       activation = 'softmax'))\n    \n    # Compiling the ANN model\n    cv_model.compile(optimizer = 'adam', \n                     loss = 'categorical_crossentropy', \n                     metrics = ['accuracy'])\n    \n    # Fitting the ANN model\n    cv_model.fit(X_train, y_train, batch_size = 10, \n                 nb_epoch = 30, verbose=1,\n                 validation_data=(X_test, y_test))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=45, activation=\"relu\", input_dim=90, kernel_initializer=\"uniform\")`\n  app.launch_new_instance()\n/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=45, activation=\"relu\", kernel_initializer=\"uniform\")`\n/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=4, activation=\"softmax\", kernel_initializer=\"uniform\")`\n/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n  warnings.warn('The `nb_epoch` argument in `fit` '\n"}, {"output_type": "stream", "name": "stdout", "text": "Train on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 851us/step - loss: 1.3708 - acc: 0.6075 - val_loss: 1.3467 - val_acc: 0.6129\nEpoch 2/30\n186/186 [==============================] - 0s 160us/step - loss: 1.2517 - acc: 0.7204 - val_loss: 1.1593 - val_acc: 0.5645\nEpoch 3/30\n186/186 [==============================] - 0s 162us/step - loss: 1.0099 - acc: 0.6720 - val_loss: 0.9411 - val_acc: 0.6129\nEpoch 4/30\n186/186 [==============================] - 0s 163us/step - loss: 0.7783 - acc: 0.7366 - val_loss: 0.7273 - val_acc: 0.7419\nEpoch 5/30\n186/186 [==============================] - 0s 166us/step - loss: 0.5811 - acc: 0.7903 - val_loss: 0.5778 - val_acc: 0.7581\nEpoch 6/30\n186/186 [==============================] - 0s 162us/step - loss: 0.4454 - acc: 0.8280 - val_loss: 0.5308 - val_acc: 0.7581\nEpoch 7/30\n186/186 [==============================] - 0s 165us/step - loss: 0.3612 - acc: 0.8763 - val_loss: 0.5060 - val_acc: 0.7903\nEpoch 8/30\n186/186 [==============================] - 0s 167us/step - loss: 0.2859 - acc: 0.8978 - val_loss: 0.4943 - val_acc: 0.8065\nEpoch 9/30\n186/186 [==============================] - 0s 165us/step - loss: 0.2412 - acc: 0.9247 - val_loss: 0.4945 - val_acc: 0.8065\nEpoch 10/30\n186/186 [==============================] - 0s 161us/step - loss: 0.2039 - acc: 0.9570 - val_loss: 0.5017 - val_acc: 0.7903\nEpoch 11/30\n186/186 [==============================] - 0s 170us/step - loss: 0.1716 - acc: 0.9570 - val_loss: 0.5062 - val_acc: 0.8065\nEpoch 12/30\n186/186 [==============================] - 0s 166us/step - loss: 0.1472 - acc: 0.9624 - val_loss: 0.5155 - val_acc: 0.7742\nEpoch 13/30\n186/186 [==============================] - 0s 160us/step - loss: 0.1279 - acc: 0.9731 - val_loss: 0.5085 - val_acc: 0.8065\nEpoch 14/30\n186/186 [==============================] - 0s 159us/step - loss: 0.1037 - acc: 0.9731 - val_loss: 0.5258 - val_acc: 0.8226\nEpoch 15/30\n186/186 [==============================] - 0s 163us/step - loss: 0.0900 - acc: 0.9839 - val_loss: 0.5239 - val_acc: 0.8387\nEpoch 16/30\n186/186 [==============================] - 0s 162us/step - loss: 0.0757 - acc: 0.9839 - val_loss: 0.5490 - val_acc: 0.8548\nEpoch 17/30\n186/186 [==============================] - 0s 175us/step - loss: 0.0622 - acc: 0.9892 - val_loss: 0.5613 - val_acc: 0.8548\nEpoch 18/30\n186/186 [==============================] - 0s 160us/step - loss: 0.0535 - acc: 0.9946 - val_loss: 0.5786 - val_acc: 0.8548\nEpoch 19/30\n186/186 [==============================] - 0s 165us/step - loss: 0.0449 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.8387\nEpoch 20/30\n186/186 [==============================] - 0s 172us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.8387\nEpoch 21/30\n186/186 [==============================] - 0s 162us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.6253 - val_acc: 0.8387\nEpoch 22/30\n186/186 [==============================] - 0s 163us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.6508 - val_acc: 0.8387\nEpoch 23/30\n186/186 [==============================] - 0s 163us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.6609 - val_acc: 0.8548\nEpoch 24/30\n186/186 [==============================] - 0s 159us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.8387\nEpoch 25/30\n186/186 [==============================] - 0s 164us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6940 - val_acc: 0.8387\nEpoch 26/30\n186/186 [==============================] - 0s 158us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.7226 - val_acc: 0.8387\nEpoch 27/30\n186/186 [==============================] - 0s 159us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.7218 - val_acc: 0.8387\nEpoch 28/30\n186/186 [==============================] - 0s 165us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.7377 - val_acc: 0.8387\nEpoch 29/30\n186/186 [==============================] - 0s 163us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.7490 - val_acc: 0.8387\nEpoch 30/30\n186/186 [==============================] - 0s 160us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 0.8387\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 964us/step - loss: 1.3719 - acc: 0.4462 - val_loss: 1.3468 - val_acc: 0.6290\nEpoch 2/30\n186/186 [==============================] - 0s 166us/step - loss: 1.2559 - acc: 0.7634 - val_loss: 1.1747 - val_acc: 0.6613\nEpoch 3/30\n186/186 [==============================] - 0s 165us/step - loss: 1.0355 - acc: 0.7312 - val_loss: 0.9747 - val_acc: 0.7258\nEpoch 4/30\n186/186 [==============================] - 0s 172us/step - loss: 0.8042 - acc: 0.7796 - val_loss: 0.7379 - val_acc: 0.7419\nEpoch 5/30\n186/186 [==============================] - 0s 172us/step - loss: 0.5814 - acc: 0.8387 - val_loss: 0.5886 - val_acc: 0.7419\nEpoch 6/30\n186/186 [==============================] - 0s 166us/step - loss: 0.4398 - acc: 0.8602 - val_loss: 0.5124 - val_acc: 0.7903\nEpoch 7/30\n186/186 [==============================] - 0s 168us/step - loss: 0.3578 - acc: 0.8871 - val_loss: 0.5219 - val_acc: 0.7258\nEpoch 8/30\n186/186 [==============================] - 0s 162us/step - loss: 0.2872 - acc: 0.9140 - val_loss: 0.5183 - val_acc: 0.7742\nEpoch 9/30\n186/186 [==============================] - 0s 162us/step - loss: 0.2356 - acc: 0.9409 - val_loss: 0.5139 - val_acc: 0.7903\nEpoch 10/30\n186/186 [==============================] - 0s 175us/step - loss: 0.2103 - acc: 0.9355 - val_loss: 0.5502 - val_acc: 0.8065\nEpoch 11/30\n186/186 [==============================] - 0s 172us/step - loss: 0.1757 - acc: 0.9624 - val_loss: 0.5321 - val_acc: 0.8226\nEpoch 12/30\n186/186 [==============================] - 0s 167us/step - loss: 0.1489 - acc: 0.9677 - val_loss: 0.5746 - val_acc: 0.8226\nEpoch 13/30\n186/186 [==============================] - 0s 167us/step - loss: 0.1242 - acc: 0.9731 - val_loss: 0.5811 - val_acc: 0.7903\nEpoch 14/30\n186/186 [==============================] - 0s 164us/step - loss: 0.1090 - acc: 0.9785 - val_loss: 0.5908 - val_acc: 0.8065\nEpoch 15/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0983 - acc: 0.9785 - val_loss: 0.6186 - val_acc: 0.8065\nEpoch 16/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0943 - acc: 0.9677 - val_loss: 0.6341 - val_acc: 0.8226\nEpoch 17/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0701 - acc: 0.9946 - val_loss: 0.6376 - val_acc: 0.8065\nEpoch 18/30\n186/186 [==============================] - 0s 162us/step - loss: 0.0611 - acc: 0.9892 - val_loss: 0.6464 - val_acc: 0.8065\nEpoch 19/30\n186/186 [==============================] - 0s 161us/step - loss: 0.0610 - acc: 0.9839 - val_loss: 0.6702 - val_acc: 0.8226\nEpoch 20/30\n186/186 [==============================] - 0s 161us/step - loss: 0.0512 - acc: 0.9839 - val_loss: 0.6732 - val_acc: 0.8226\nEpoch 21/30\n186/186 [==============================] - 0s 164us/step - loss: 0.0449 - acc: 0.9946 - val_loss: 0.7074 - val_acc: 0.8387\nEpoch 22/30\n186/186 [==============================] - 0s 164us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.8387\nEpoch 23/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.7070 - val_acc: 0.8387\nEpoch 24/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.8226\nEpoch 25/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 0.8226\nEpoch 26/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.8387\nEpoch 27/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.7741 - val_acc: 0.8387\nEpoch 28/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.8226\nEpoch 29/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.7928 - val_acc: 0.8387\nEpoch 30/30\n186/186 [==============================] - 0s 165us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.7964 - val_acc: 0.8387\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n"}, {"output_type": "stream", "name": "stdout", "text": "186/186 [==============================] - 0s 1ms/step - loss: 1.3711 - acc: 0.4624 - val_loss: 1.3427 - val_acc: 0.5323\nEpoch 2/30\n186/186 [==============================] - 0s 176us/step - loss: 1.2449 - acc: 0.6398 - val_loss: 1.1463 - val_acc: 0.5806\nEpoch 3/30\n186/186 [==============================] - 0s 162us/step - loss: 0.9933 - acc: 0.6022 - val_loss: 0.9157 - val_acc: 0.5806\nEpoch 4/30\n186/186 [==============================] - 0s 166us/step - loss: 0.7937 - acc: 0.6559 - val_loss: 0.7496 - val_acc: 0.6452\nEpoch 5/30\n186/186 [==============================] - 0s 163us/step - loss: 0.6352 - acc: 0.7312 - val_loss: 0.6440 - val_acc: 0.8548\nEpoch 6/30\n186/186 [==============================] - 0s 169us/step - loss: 0.5178 - acc: 0.8548 - val_loss: 0.5888 - val_acc: 0.7742\nEpoch 7/30\n186/186 [==============================] - 0s 169us/step - loss: 0.4245 - acc: 0.8656 - val_loss: 0.5675 - val_acc: 0.7258\nEpoch 8/30\n186/186 [==============================] - 0s 174us/step - loss: 0.3417 - acc: 0.9086 - val_loss: 0.5451 - val_acc: 0.7419\nEpoch 9/30\n186/186 [==============================] - 0s 177us/step - loss: 0.2878 - acc: 0.9140 - val_loss: 0.5455 - val_acc: 0.7097\nEpoch 10/30\n186/186 [==============================] - 0s 188us/step - loss: 0.2388 - acc: 0.9355 - val_loss: 0.5529 - val_acc: 0.7258\nEpoch 11/30\n186/186 [==============================] - 0s 175us/step - loss: 0.1956 - acc: 0.9624 - val_loss: 0.5424 - val_acc: 0.7419\nEpoch 12/30\n186/186 [==============================] - 0s 171us/step - loss: 0.1740 - acc: 0.9624 - val_loss: 0.5515 - val_acc: 0.7903\nEpoch 13/30\n186/186 [==============================] - 0s 173us/step - loss: 0.1432 - acc: 0.9731 - val_loss: 0.5582 - val_acc: 0.7903\nEpoch 14/30\n186/186 [==============================] - 0s 202us/step - loss: 0.1266 - acc: 0.9731 - val_loss: 0.5846 - val_acc: 0.8065\nEpoch 15/30\n186/186 [==============================] - 0s 173us/step - loss: 0.1131 - acc: 0.9785 - val_loss: 0.5994 - val_acc: 0.7903\nEpoch 16/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0888 - acc: 0.9839 - val_loss: 0.6081 - val_acc: 0.8226\nEpoch 17/30\n186/186 [==============================] - 0s 173us/step - loss: 0.0784 - acc: 0.9785 - val_loss: 0.6116 - val_acc: 0.8065\nEpoch 18/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0709 - acc: 0.9892 - val_loss: 0.6084 - val_acc: 0.8226\nEpoch 19/30\n186/186 [==============================] - 0s 172us/step - loss: 0.0596 - acc: 0.9839 - val_loss: 0.6064 - val_acc: 0.8226\nEpoch 20/30\n186/186 [==============================] - 0s 175us/step - loss: 0.0564 - acc: 0.9946 - val_loss: 0.6043 - val_acc: 0.8226\nEpoch 21/30\n186/186 [==============================] - 0s 202us/step - loss: 0.0480 - acc: 0.9892 - val_loss: 0.6337 - val_acc: 0.8226\nEpoch 22/30\n186/186 [==============================] - 0s 173us/step - loss: 0.0407 - acc: 0.9946 - val_loss: 0.6486 - val_acc: 0.8226\nEpoch 23/30\n186/186 [==============================] - 0s 182us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 0.6493 - val_acc: 0.8226\nEpoch 24/30\n186/186 [==============================] - 0s 182us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.6583 - val_acc: 0.8226\nEpoch 25/30\n186/186 [==============================] - 0s 174us/step - loss: 0.0301 - acc: 0.9946 - val_loss: 0.6889 - val_acc: 0.8226\nEpoch 26/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0277 - acc: 0.9946 - val_loss: 0.6966 - val_acc: 0.8226\nEpoch 27/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.6939 - val_acc: 0.8226\nEpoch 28/30\n186/186 [==============================] - 0s 174us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.6957 - val_acc: 0.8226\nEpoch 29/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.7153 - val_acc: 0.8226\nEpoch 30/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.7177 - val_acc: 0.8226\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 1ms/step - loss: 1.3698 - acc: 0.4409 - val_loss: 1.3440 - val_acc: 0.5645\nEpoch 2/30\n186/186 [==============================] - 0s 163us/step - loss: 1.2318 - acc: 0.6613 - val_loss: 1.1657 - val_acc: 0.6452\nEpoch 3/30\n186/186 [==============================] - 0s 164us/step - loss: 1.0356 - acc: 0.7419 - val_loss: 0.9868 - val_acc: 0.7258\nEpoch 4/30\n186/186 [==============================] - 0s 165us/step - loss: 0.8222 - acc: 0.7581 - val_loss: 0.7545 - val_acc: 0.7581\nEpoch 5/30\n186/186 [==============================] - 0s 164us/step - loss: 0.6130 - acc: 0.8226 - val_loss: 0.5898 - val_acc: 0.7581\nEpoch 6/30\n186/186 [==============================] - 0s 162us/step - loss: 0.4730 - acc: 0.8495 - val_loss: 0.5197 - val_acc: 0.7903\nEpoch 7/30\n186/186 [==============================] - 0s 164us/step - loss: 0.3769 - acc: 0.8602 - val_loss: 0.4759 - val_acc: 0.7581\nEpoch 8/30\n186/186 [==============================] - 0s 164us/step - loss: 0.3201 - acc: 0.8871 - val_loss: 0.4552 - val_acc: 0.7742\nEpoch 9/30\n186/186 [==============================] - 0s 160us/step - loss: 0.2695 - acc: 0.9032 - val_loss: 0.4277 - val_acc: 0.7742\nEpoch 10/30\n186/186 [==============================] - 0s 169us/step - loss: 0.2287 - acc: 0.9194 - val_loss: 0.4469 - val_acc: 0.7903\nEpoch 11/30\n186/186 [==============================] - 0s 182us/step - loss: 0.1927 - acc: 0.9462 - val_loss: 0.4306 - val_acc: 0.8065\nEpoch 12/30\n186/186 [==============================] - 0s 168us/step - loss: 0.1642 - acc: 0.9570 - val_loss: 0.4323 - val_acc: 0.8065\nEpoch 13/30\n186/186 [==============================] - 0s 168us/step - loss: 0.1422 - acc: 0.9624 - val_loss: 0.4646 - val_acc: 0.8226\nEpoch 14/30\n186/186 [==============================] - 0s 166us/step - loss: 0.1214 - acc: 0.9839 - val_loss: 0.4527 - val_acc: 0.8226\nEpoch 15/30\n186/186 [==============================] - 0s 170us/step - loss: 0.1049 - acc: 0.9731 - val_loss: 0.4384 - val_acc: 0.8387\nEpoch 16/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0846 - acc: 0.9946 - val_loss: 0.4596 - val_acc: 0.8548\nEpoch 17/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0701 - acc: 0.9892 - val_loss: 0.4457 - val_acc: 0.8548\nEpoch 18/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0605 - acc: 0.9892 - val_loss: 0.4574 - val_acc: 0.8387\nEpoch 19/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0567 - acc: 0.9946 - val_loss: 0.4872 - val_acc: 0.8548\nEpoch 20/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.4545 - val_acc: 0.8548\nEpoch 21/30\n186/186 [==============================] - 0s 172us/step - loss: 0.0395 - acc: 0.9946 - val_loss: 0.5011 - val_acc: 0.8548\nEpoch 22/30\n186/186 [==============================] - 0s 173us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.4916 - val_acc: 0.8548\nEpoch 23/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.4975 - val_acc: 0.8548\nEpoch 24/30\n186/186 [==============================] - 0s 178us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.5227 - val_acc: 0.8387\nEpoch 25/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.5143 - val_acc: 0.8548\nEpoch 26/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.5303 - val_acc: 0.8548\nEpoch 27/30\n186/186 [==============================] - 0s 178us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.8387\nEpoch 28/30\n186/186 [==============================] - 0s 174us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.5483 - val_acc: 0.8548\nEpoch 29/30\n186/186 [==============================] - 0s 175us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.5559 - val_acc: 0.8387\nEpoch 30/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.8387\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 1ms/step - loss: 1.3646 - acc: 0.4462 - val_loss: 1.3262 - val_acc: 0.4677\nEpoch 2/30\n186/186 [==============================] - 0s 176us/step - loss: 1.2084 - acc: 0.5161 - val_loss: 1.1321 - val_acc: 0.4677\nEpoch 3/30\n186/186 [==============================] - 0s 169us/step - loss: 1.0178 - acc: 0.5161 - val_loss: 0.9608 - val_acc: 0.5484\nEpoch 4/30\n186/186 [==============================] - 0s 166us/step - loss: 0.8396 - acc: 0.6075 - val_loss: 0.7978 - val_acc: 0.6452\nEpoch 5/30\n186/186 [==============================] - 0s 165us/step - loss: 0.6820 - acc: 0.7151 - val_loss: 0.6736 - val_acc: 0.7742\nEpoch 6/30\n186/186 [==============================] - 0s 180us/step - loss: 0.5472 - acc: 0.8226 - val_loss: 0.6121 - val_acc: 0.7903\nEpoch 7/30\n186/186 [==============================] - 0s 170us/step - loss: 0.4536 - acc: 0.8387 - val_loss: 0.5545 - val_acc: 0.7258\nEpoch 8/30\n186/186 [==============================] - 0s 170us/step - loss: 0.3744 - acc: 0.8710 - val_loss: 0.5408 - val_acc: 0.7742\nEpoch 9/30\n186/186 [==============================] - 0s 171us/step - loss: 0.3151 - acc: 0.8978 - val_loss: 0.5172 - val_acc: 0.7581\nEpoch 10/30\n186/186 [==============================] - 0s 175us/step - loss: 0.2662 - acc: 0.9247 - val_loss: 0.5148 - val_acc: 0.8065\nEpoch 11/30\n186/186 [==============================] - 0s 174us/step - loss: 0.2196 - acc: 0.9462 - val_loss: 0.5265 - val_acc: 0.7742\nEpoch 12/30\n186/186 [==============================] - 0s 170us/step - loss: 0.1879 - acc: 0.9570 - val_loss: 0.5163 - val_acc: 0.8226\nEpoch 13/30\n186/186 [==============================] - 0s 171us/step - loss: 0.1563 - acc: 0.9624 - val_loss: 0.5060 - val_acc: 0.8226\nEpoch 14/30\n186/186 [==============================] - 0s 171us/step - loss: 0.1396 - acc: 0.9624 - val_loss: 0.5134 - val_acc: 0.8387\nEpoch 15/30\n186/186 [==============================] - 0s 169us/step - loss: 0.1148 - acc: 0.9839 - val_loss: 0.5176 - val_acc: 0.8387\nEpoch 16/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0959 - acc: 0.9839 - val_loss: 0.5529 - val_acc: 0.8548\nEpoch 17/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0806 - acc: 0.9946 - val_loss: 0.5356 - val_acc: 0.8710\nEpoch 18/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0687 - acc: 0.9892 - val_loss: 0.5538 - val_acc: 0.8710\nEpoch 19/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0585 - acc: 0.9892 - val_loss: 0.5698 - val_acc: 0.8548\nEpoch 20/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0547 - acc: 0.9946 - val_loss: 0.5920 - val_acc: 0.8710\nEpoch 21/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.8710\nEpoch 22/30\n186/186 [==============================] - 0s 165us/step - loss: 0.0467 - acc: 0.9892 - val_loss: 0.6008 - val_acc: 0.8710\nEpoch 23/30\n186/186 [==============================] - 0s 164us/step - loss: 0.0349 - acc: 0.9946 - val_loss: 0.6127 - val_acc: 0.8710\nEpoch 24/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.6321 - val_acc: 0.8710\nEpoch 25/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 0.8710\nEpoch 26/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.6888 - val_acc: 0.8710\nEpoch 27/30\n186/186 [==============================] - 0s 163us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.6758 - val_acc: 0.8548\nEpoch 28/30\n186/186 [==============================] - 0s 162us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6946 - val_acc: 0.8548\nEpoch 29/30\n186/186 [==============================] - 0s 162us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.7017 - val_acc: 0.8548\nEpoch 30/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.8548\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 1ms/step - loss: 1.3695 - acc: 0.5430 - val_loss: 1.3436 - val_acc: 0.6290\nEpoch 2/30\n186/186 [==============================] - 0s 171us/step - loss: 1.2356 - acc: 0.7151 - val_loss: 1.1500 - val_acc: 0.5161\nEpoch 3/30\n186/186 [==============================] - 0s 174us/step - loss: 1.0077 - acc: 0.6559 - val_loss: 0.9436 - val_acc: 0.6613\nEpoch 4/30\n186/186 [==============================] - 0s 172us/step - loss: 0.7969 - acc: 0.7097 - val_loss: 0.7350 - val_acc: 0.7097\nEpoch 5/30\n186/186 [==============================] - 0s 172us/step - loss: 0.5893 - acc: 0.7957 - val_loss: 0.6096 - val_acc: 0.7097\nEpoch 6/30\n186/186 [==============================] - 0s 170us/step - loss: 0.4550 - acc: 0.8602 - val_loss: 0.5746 - val_acc: 0.7097\nEpoch 7/30\n186/186 [==============================] - 0s 172us/step - loss: 0.3645 - acc: 0.8978 - val_loss: 0.5518 - val_acc: 0.7097\nEpoch 8/30\n186/186 [==============================] - 0s 168us/step - loss: 0.3027 - acc: 0.9032 - val_loss: 0.5709 - val_acc: 0.6935\nEpoch 9/30\n186/186 [==============================] - 0s 170us/step - loss: 0.2704 - acc: 0.9247 - val_loss: 0.5872 - val_acc: 0.7742\nEpoch 10/30\n186/186 [==============================] - 0s 170us/step - loss: 0.2297 - acc: 0.9409 - val_loss: 0.5758 - val_acc: 0.7742\nEpoch 11/30\n186/186 [==============================] - 0s 166us/step - loss: 0.2015 - acc: 0.9409 - val_loss: 0.6030 - val_acc: 0.7581\nEpoch 12/30\n186/186 [==============================] - 0s 174us/step - loss: 0.1753 - acc: 0.9570 - val_loss: 0.6274 - val_acc: 0.7581\nEpoch 13/30\n186/186 [==============================] - 0s 172us/step - loss: 0.1551 - acc: 0.9624 - val_loss: 0.6150 - val_acc: 0.7742\nEpoch 14/30\n186/186 [==============================] - 0s 173us/step - loss: 0.1384 - acc: 0.9731 - val_loss: 0.6426 - val_acc: 0.7742\nEpoch 15/30\n186/186 [==============================] - 0s 172us/step - loss: 0.1249 - acc: 0.9731 - val_loss: 0.6506 - val_acc: 0.7903\nEpoch 16/30\n186/186 [==============================] - 0s 170us/step - loss: 0.1150 - acc: 0.9731 - val_loss: 0.6438 - val_acc: 0.8065\nEpoch 17/30\n186/186 [==============================] - 0s 176us/step - loss: 0.1000 - acc: 0.9839 - val_loss: 0.6784 - val_acc: 0.7903\nEpoch 18/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0838 - acc: 0.9839 - val_loss: 0.6819 - val_acc: 0.8226\nEpoch 19/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0730 - acc: 0.9839 - val_loss: 0.6517 - val_acc: 0.8226\nEpoch 20/30\n186/186 [==============================] - 0s 168us/step - loss: 0.0625 - acc: 0.9892 - val_loss: 0.7026 - val_acc: 0.8387\nEpoch 21/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0563 - acc: 0.9946 - val_loss: 0.7019 - val_acc: 0.8387\nEpoch 22/30\n186/186 [==============================] - 0s 168us/step - loss: 0.0492 - acc: 0.9946 - val_loss: 0.7151 - val_acc: 0.8387\nEpoch 23/30\n186/186 [==============================] - 0s 165us/step - loss: 0.0464 - acc: 0.9892 - val_loss: 0.7470 - val_acc: 0.8387\nEpoch 24/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0408 - acc: 1.0000 - val_loss: 0.7294 - val_acc: 0.8387\nEpoch 25/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0358 - acc: 0.9946 - val_loss: 0.7357 - val_acc: 0.8387\nEpoch 26/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.7822 - val_acc: 0.8387\nEpoch 27/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.7873 - val_acc: 0.8387\nEpoch 28/30\n186/186 [==============================] - 0s 167us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 0.8387\nEpoch 29/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.7871 - val_acc: 0.8387\nEpoch 30/30\n186/186 [==============================] - 0s 166us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.8099 - val_acc: 0.8387\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n"}, {"output_type": "stream", "name": "stdout", "text": "186/186 [==============================] - 0s 2ms/step - loss: 1.3672 - acc: 0.5215 - val_loss: 1.3368 - val_acc: 0.5323\nEpoch 2/30\n186/186 [==============================] - 0s 174us/step - loss: 1.2142 - acc: 0.6129 - val_loss: 1.1276 - val_acc: 0.5323\nEpoch 3/30\n186/186 [==============================] - 0s 181us/step - loss: 0.9851 - acc: 0.5860 - val_loss: 0.9208 - val_acc: 0.6774\nEpoch 4/30\n186/186 [==============================] - 0s 175us/step - loss: 0.7823 - acc: 0.7204 - val_loss: 0.7566 - val_acc: 0.6935\nEpoch 5/30\n186/186 [==============================] - 0s 179us/step - loss: 0.6117 - acc: 0.8065 - val_loss: 0.6422 - val_acc: 0.6935\nEpoch 6/30\n186/186 [==============================] - 0s 173us/step - loss: 0.4796 - acc: 0.8441 - val_loss: 0.5819 - val_acc: 0.6935\nEpoch 7/30\n186/186 [==============================] - 0s 171us/step - loss: 0.3925 - acc: 0.8925 - val_loss: 0.5543 - val_acc: 0.6774\nEpoch 8/30\n186/186 [==============================] - 0s 171us/step - loss: 0.3210 - acc: 0.9086 - val_loss: 0.5781 - val_acc: 0.7258\nEpoch 9/30\n186/186 [==============================] - 0s 173us/step - loss: 0.2692 - acc: 0.9301 - val_loss: 0.5448 - val_acc: 0.7742\nEpoch 10/30\n186/186 [==============================] - 0s 169us/step - loss: 0.2335 - acc: 0.9355 - val_loss: 0.5592 - val_acc: 0.7903\nEpoch 11/30\n186/186 [==============================] - 0s 170us/step - loss: 0.1973 - acc: 0.9409 - val_loss: 0.5538 - val_acc: 0.7903\nEpoch 12/30\n186/186 [==============================] - 0s 169us/step - loss: 0.1815 - acc: 0.9570 - val_loss: 0.5636 - val_acc: 0.7903\nEpoch 13/30\n186/186 [==============================] - 0s 171us/step - loss: 0.1589 - acc: 0.9624 - val_loss: 0.5476 - val_acc: 0.7903\nEpoch 14/30\n186/186 [==============================] - 0s 179us/step - loss: 0.1408 - acc: 0.9677 - val_loss: 0.5824 - val_acc: 0.7903\nEpoch 15/30\n186/186 [==============================] - 0s 179us/step - loss: 0.1205 - acc: 0.9731 - val_loss: 0.5761 - val_acc: 0.7742\nEpoch 16/30\n186/186 [==============================] - 0s 178us/step - loss: 0.1056 - acc: 0.9731 - val_loss: 0.5665 - val_acc: 0.7903\nEpoch 17/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0877 - acc: 0.9785 - val_loss: 0.5901 - val_acc: 0.7742\nEpoch 18/30\n186/186 [==============================] - 0s 178us/step - loss: 0.0764 - acc: 0.9785 - val_loss: 0.5858 - val_acc: 0.8226\nEpoch 19/30\n186/186 [==============================] - 0s 174us/step - loss: 0.0677 - acc: 0.9892 - val_loss: 0.5701 - val_acc: 0.8065\nEpoch 20/30\n186/186 [==============================] - 0s 177us/step - loss: 0.0588 - acc: 0.9839 - val_loss: 0.5963 - val_acc: 0.8226\nEpoch 21/30\n186/186 [==============================] - 0s 172us/step - loss: 0.0516 - acc: 0.9946 - val_loss: 0.5974 - val_acc: 0.8226\nEpoch 22/30\n186/186 [==============================] - 0s 174us/step - loss: 0.0480 - acc: 0.9892 - val_loss: 0.6138 - val_acc: 0.8226\nEpoch 23/30\n186/186 [==============================] - 0s 172us/step - loss: 0.0395 - acc: 0.9946 - val_loss: 0.6497 - val_acc: 0.8226\nEpoch 24/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0368 - acc: 1.0000 - val_loss: 0.6203 - val_acc: 0.8226\nEpoch 25/30\n186/186 [==============================] - 0s 174us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.6317 - val_acc: 0.8226\nEpoch 26/30\n186/186 [==============================] - 0s 171us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 0.8226\nEpoch 27/30\n186/186 [==============================] - 0s 170us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.6439 - val_acc: 0.8226\nEpoch 28/30\n186/186 [==============================] - 0s 168us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6550 - val_acc: 0.8387\nEpoch 29/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.6757 - val_acc: 0.8226\nEpoch 30/30\n186/186 [==============================] - 0s 169us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6640 - val_acc: 0.8387\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 2ms/step - loss: 1.3718 - acc: 0.5591 - val_loss: 1.3450 - val_acc: 0.6452\nEpoch 2/30\n186/186 [==============================] - 0s 170us/step - loss: 1.2608 - acc: 0.6237 - val_loss: 1.1594 - val_acc: 0.6774\nEpoch 3/30\n186/186 [==============================] - 0s 168us/step - loss: 0.9974 - acc: 0.7204 - val_loss: 0.9036 - val_acc: 0.6935\nEpoch 4/30\n186/186 [==============================] - 0s 181us/step - loss: 0.7756 - acc: 0.7258 - val_loss: 0.7042 - val_acc: 0.6935\nEpoch 5/30\n186/186 [==============================] - 0s 175us/step - loss: 0.5938 - acc: 0.8333 - val_loss: 0.6049 - val_acc: 0.7258\nEpoch 6/30\n186/186 [==============================] - 0s 185us/step - loss: 0.4523 - acc: 0.8548 - val_loss: 0.5322 - val_acc: 0.7097\nEpoch 7/30\n186/186 [==============================] - 0s 178us/step - loss: 0.3573 - acc: 0.8925 - val_loss: 0.5158 - val_acc: 0.7419\nEpoch 8/30\n186/186 [==============================] - 0s 176us/step - loss: 0.2969 - acc: 0.9140 - val_loss: 0.5017 - val_acc: 0.8065\nEpoch 9/30\n186/186 [==============================] - 0s 172us/step - loss: 0.2512 - acc: 0.9301 - val_loss: 0.4985 - val_acc: 0.8226\nEpoch 10/30\n186/186 [==============================] - 0s 176us/step - loss: 0.2147 - acc: 0.9301 - val_loss: 0.4816 - val_acc: 0.8065\nEpoch 11/30\n186/186 [==============================] - 0s 175us/step - loss: 0.1862 - acc: 0.9462 - val_loss: 0.5051 - val_acc: 0.8226\nEpoch 12/30\n186/186 [==============================] - 0s 180us/step - loss: 0.1564 - acc: 0.9731 - val_loss: 0.5043 - val_acc: 0.8387\nEpoch 13/30\n186/186 [==============================] - 0s 170us/step - loss: 0.1393 - acc: 0.9731 - val_loss: 0.4787 - val_acc: 0.8387\nEpoch 14/30\n186/186 [==============================] - 0s 182us/step - loss: 0.1220 - acc: 0.9731 - val_loss: 0.5067 - val_acc: 0.8548\nEpoch 15/30\n186/186 [==============================] - 0s 186us/step - loss: 0.1083 - acc: 0.9731 - val_loss: 0.5097 - val_acc: 0.8226\nEpoch 16/30\n186/186 [==============================] - 0s 185us/step - loss: 0.0943 - acc: 0.9731 - val_loss: 0.5233 - val_acc: 0.8548\nEpoch 17/30\n186/186 [==============================] - 0s 182us/step - loss: 0.0779 - acc: 0.9839 - val_loss: 0.5401 - val_acc: 0.8226\nEpoch 18/30\n186/186 [==============================] - 0s 189us/step - loss: 0.0706 - acc: 0.9892 - val_loss: 0.5405 - val_acc: 0.8387\nEpoch 19/30\n186/186 [==============================] - 0s 186us/step - loss: 0.0669 - acc: 0.9731 - val_loss: 0.5913 - val_acc: 0.8387\nEpoch 20/30\n186/186 [==============================] - 0s 191us/step - loss: 0.0574 - acc: 0.9946 - val_loss: 0.5529 - val_acc: 0.8548\nEpoch 21/30\n186/186 [==============================] - 0s 182us/step - loss: 0.0507 - acc: 0.9892 - val_loss: 0.5998 - val_acc: 0.8548\nEpoch 22/30\n186/186 [==============================] - 0s 189us/step - loss: 0.0460 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.8548\nEpoch 23/30\n186/186 [==============================] - 0s 188us/step - loss: 0.0373 - acc: 0.9946 - val_loss: 0.5820 - val_acc: 0.8548\nEpoch 24/30\n186/186 [==============================] - 0s 179us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.6086 - val_acc: 0.8548\nEpoch 25/30\n186/186 [==============================] - 0s 180us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.6357 - val_acc: 0.8548\nEpoch 26/30\n186/186 [==============================] - 0s 185us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.8548\nEpoch 27/30\n186/186 [==============================] - 0s 184us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.8548\nEpoch 28/30\n186/186 [==============================] - 0s 186us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.8548\nEpoch 29/30\n186/186 [==============================] - 0s 178us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6724 - val_acc: 0.8387\nEpoch 30/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6977 - val_acc: 0.8387\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 2ms/step - loss: 1.3668 - acc: 0.4355 - val_loss: 1.3334 - val_acc: 0.4516\nEpoch 2/30\n186/186 [==============================] - 0s 187us/step - loss: 1.2365 - acc: 0.5215 - val_loss: 1.1327 - val_acc: 0.5000\nEpoch 3/30\n186/186 [==============================] - 0s 184us/step - loss: 1.0040 - acc: 0.5860 - val_loss: 0.9200 - val_acc: 0.6452\nEpoch 4/30\n186/186 [==============================] - 0s 181us/step - loss: 0.8278 - acc: 0.6935 - val_loss: 0.7793 - val_acc: 0.7258\nEpoch 5/30\n186/186 [==============================] - 0s 182us/step - loss: 0.6804 - acc: 0.7688 - val_loss: 0.6691 - val_acc: 0.8065\nEpoch 6/30\n186/186 [==============================] - 0s 184us/step - loss: 0.5430 - acc: 0.8495 - val_loss: 0.6031 - val_acc: 0.7581\nEpoch 7/30\n186/186 [==============================] - 0s 193us/step - loss: 0.4244 - acc: 0.8763 - val_loss: 0.5339 - val_acc: 0.7581\nEpoch 8/30\n186/186 [==============================] - 0s 176us/step - loss: 0.3392 - acc: 0.8925 - val_loss: 0.4909 - val_acc: 0.7903\nEpoch 9/30\n186/186 [==============================] - 0s 177us/step - loss: 0.2779 - acc: 0.9086 - val_loss: 0.4778 - val_acc: 0.8226\nEpoch 10/30\n186/186 [==============================] - 0s 176us/step - loss: 0.2286 - acc: 0.9355 - val_loss: 0.4531 - val_acc: 0.8226\nEpoch 11/30\n186/186 [==============================] - 0s 176us/step - loss: 0.1944 - acc: 0.9516 - val_loss: 0.4330 - val_acc: 0.8548\nEpoch 12/30\n186/186 [==============================] - 0s 180us/step - loss: 0.1616 - acc: 0.9516 - val_loss: 0.4661 - val_acc: 0.8548\nEpoch 13/30\n186/186 [==============================] - 0s 172us/step - loss: 0.1346 - acc: 0.9624 - val_loss: 0.4439 - val_acc: 0.8548\nEpoch 14/30\n186/186 [==============================] - 0s 195us/step - loss: 0.1192 - acc: 0.9677 - val_loss: 0.4765 - val_acc: 0.8710\nEpoch 15/30\n186/186 [==============================] - 0s 182us/step - loss: 0.0993 - acc: 0.9839 - val_loss: 0.4558 - val_acc: 0.8710\nEpoch 16/30\n186/186 [==============================] - 0s 180us/step - loss: 0.0883 - acc: 0.9785 - val_loss: 0.5101 - val_acc: 0.8548\nEpoch 17/30\n186/186 [==============================] - 0s 184us/step - loss: 0.0795 - acc: 0.9785 - val_loss: 0.4711 - val_acc: 0.8871\nEpoch 18/30\n186/186 [==============================] - 0s 188us/step - loss: 0.0614 - acc: 0.9946 - val_loss: 0.5187 - val_acc: 0.8710\nEpoch 19/30\n186/186 [==============================] - 0s 183us/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.8710\nEpoch 20/30\n186/186 [==============================] - 0s 183us/step - loss: 0.0500 - acc: 0.9946 - val_loss: 0.5461 - val_acc: 0.8710\nEpoch 21/30\n186/186 [==============================] - 0s 175us/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.5510 - val_acc: 0.8710\nEpoch 22/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.5422 - val_acc: 0.8710\nEpoch 23/30\n186/186 [==============================] - 0s 190us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.5750 - val_acc: 0.8710\nEpoch 24/30\n186/186 [==============================] - 0s 178us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.5828 - val_acc: 0.8710\nEpoch 25/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.5821 - val_acc: 0.8710\nEpoch 26/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.8710\nEpoch 27/30\n186/186 [==============================] - 0s 177us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6075 - val_acc: 0.8710\nEpoch 28/30\n186/186 [==============================] - 0s 179us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6196 - val_acc: 0.8710\nEpoch 29/30\n186/186 [==============================] - 0s 179us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.6150 - val_acc: 0.8548\nEpoch 30/30\n186/186 [==============================] - 0s 174us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.6270 - val_acc: 0.8710\nTrain on 186 samples, validate on 62 samples\nEpoch 1/30\n186/186 [==============================] - 0s 2ms/step - loss: 1.3720 - acc: 0.5538 - val_loss: 1.3463 - val_acc: 0.7419\nEpoch 2/30\n186/186 [==============================] - 0s 176us/step - loss: 1.2598 - acc: 0.6720 - val_loss: 1.1605 - val_acc: 0.6129\nEpoch 3/30\n186/186 [==============================] - 0s 175us/step - loss: 0.9973 - acc: 0.6183 - val_loss: 0.8929 - val_acc: 0.6452\nEpoch 4/30\n186/186 [==============================] - 0s 173us/step - loss: 0.7935 - acc: 0.7258 - val_loss: 0.7274 - val_acc: 0.7258\nEpoch 5/30\n186/186 [==============================] - 0s 172us/step - loss: 0.6259 - acc: 0.7957 - val_loss: 0.6129 - val_acc: 0.7419\nEpoch 6/30\n186/186 [==============================] - 0s 169us/step - loss: 0.5153 - acc: 0.8602 - val_loss: 0.5637 - val_acc: 0.7258\nEpoch 7/30\n186/186 [==============================] - 0s 175us/step - loss: 0.4337 - acc: 0.8495 - val_loss: 0.5348 - val_acc: 0.7419\nEpoch 8/30\n186/186 [==============================] - 0s 176us/step - loss: 0.3623 - acc: 0.8763 - val_loss: 0.5239 - val_acc: 0.7097\nEpoch 9/30\n186/186 [==============================] - 0s 174us/step - loss: 0.3056 - acc: 0.8978 - val_loss: 0.5255 - val_acc: 0.7581\nEpoch 10/30\n186/186 [==============================] - 0s 174us/step - loss: 0.2533 - acc: 0.9355 - val_loss: 0.5333 - val_acc: 0.7419\nEpoch 11/30\n186/186 [==============================] - 0s 171us/step - loss: 0.2175 - acc: 0.9462 - val_loss: 0.5274 - val_acc: 0.7581\nEpoch 12/30\n186/186 [==============================] - 0s 174us/step - loss: 0.1874 - acc: 0.9570 - val_loss: 0.5319 - val_acc: 0.7742\nEpoch 13/30\n186/186 [==============================] - 0s 175us/step - loss: 0.1580 - acc: 0.9624 - val_loss: 0.5450 - val_acc: 0.8065\nEpoch 14/30\n186/186 [==============================] - 0s 178us/step - loss: 0.1376 - acc: 0.9731 - val_loss: 0.5430 - val_acc: 0.8226\nEpoch 15/30\n186/186 [==============================] - 0s 173us/step - loss: 0.1173 - acc: 0.9731 - val_loss: 0.5324 - val_acc: 0.8226\nEpoch 16/30\n186/186 [==============================] - 0s 193us/step - loss: 0.1009 - acc: 0.9731 - val_loss: 0.5694 - val_acc: 0.8226\nEpoch 17/30\n186/186 [==============================] - 0s 181us/step - loss: 0.1017 - acc: 0.9785 - val_loss: 0.5443 - val_acc: 0.8387\nEpoch 18/30\n186/186 [==============================] - 0s 183us/step - loss: 0.0789 - acc: 0.9892 - val_loss: 0.5828 - val_acc: 0.8387\nEpoch 19/30\n186/186 [==============================] - 0s 173us/step - loss: 0.0651 - acc: 1.0000 - val_loss: 0.5708 - val_acc: 0.8387\nEpoch 20/30\n186/186 [==============================] - 0s 178us/step - loss: 0.0593 - acc: 0.9946 - val_loss: 0.5779 - val_acc: 0.8387\nEpoch 21/30\n186/186 [==============================] - 0s 181us/step - loss: 0.0501 - acc: 0.9946 - val_loss: 0.5980 - val_acc: 0.8387\nEpoch 22/30\n186/186 [==============================] - 0s 175us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.6410 - val_acc: 0.8387\nEpoch 23/30\n186/186 [==============================] - 0s 176us/step - loss: 0.0391 - acc: 1.0000 - val_loss: 0.6394 - val_acc: 0.8387\nEpoch 24/30\n186/186 [==============================] - 0s 183us/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.6448 - val_acc: 0.8387\nEpoch 25/30\n186/186 [==============================] - 0s 175us/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.6751 - val_acc: 0.8387\nEpoch 26/30\n186/186 [==============================] - 0s 179us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.6723 - val_acc: 0.8387\nEpoch 27/30\n186/186 [==============================] - 0s 203us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.6919 - val_acc: 0.8387\nEpoch 28/30\n186/186 [==============================] - 0s 182us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.7127 - val_acc: 0.8387\nEpoch 29/30\n186/186 [==============================] - 0s 177us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.8387\nEpoch 30/30\n186/186 [==============================] - 0s 186us/step - loss: 0.0217 - acc: 0.9946 - val_loss: 0.7007 - val_acc: 0.8387\n"}], "execution_count": 71}, {"source": "# save the model\ncv_model_result_path = \"/home/dsxuser/work/datasetWS_DvsEvsHvsM_512-512_git/class_4_ANN_cv_model_DvsEvsHvsM_v1.h5\"\ncv_model.save(cv_model_result_path)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 72}, {"source": "cv_model.save_weights('/home/dsxuser/work/datasetWS_DvsEvsHvsM_512-512_git/class_4_ANN_cv_model_DvsEvsHvsM_v1_weights.h5')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 73}, {"source": "## 4.2 Test the Model ", "cell_type": "markdown", "metadata": {}}, {"source": "score_train_cv = cv_model.evaluate(X_train, y_train, verbose=0)\nprint(\"Loss = \", score_train_cv[0], \", Accuracy = \", score_train_cv[1])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Loss =  0.0175027598537 , Accuracy =  1.0\n"}], "execution_count": 74}, {"source": "score_test_cv = cv_model.evaluate(X_test, y_test, verbose=0)\nprint(\"Loss = \", score_test_cv[0], \", Accuracy = \", score_test_cv[1])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Loss =  0.700656642837 , Accuracy =  0.838709665883\n"}], "execution_count": 75}, {"source": "score_val_cv = cv_model.evaluate(X_val, y_val, verbose=0)\nprint(\"Loss = \", score_val_cv[0], \", Accuracy = \", score_val_cv[1])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Loss =  0.635840713978 , Accuracy =  0.833333313465\n"}], "execution_count": 76}, {"source": "## 4.3 Accuracy Testing", "cell_type": "markdown", "metadata": {}}, {"source": "Accuracy testing of test dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "#predictions_test\npredictions_test_cv = cv_model.predict(X_test)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 77}, {"source": "y_pred_test_cv =[]\nfor i in range(len(predictions_test_cv)):\n    y_pred_test_cv.append(np.argmax(predictions_test_cv[i]))\nprint(y_pred_test_cv)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[3, 2, 3, 2, 2, 1, 0, 2, 3, 1, 1, 1, 1, 3, 3, 3, 0, 1, 3, 1, 3, 1, 2, 1, 0, 3, 0, 1, 1, 3, 1, 0, 3, 1, 2, 0, 0, 2, 0, 2, 3, 2, 1, 2, 1, 2, 3, 2, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 2, 2, 1, 2]\n"}], "execution_count": 78}, {"source": "y_test", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.]])"}, "execution_count": 79}], "execution_count": 79}, {"source": "y_test_labels_cv = [ np.where(r==1)[0][0] for r in y_test ]\ny_test_labels_cv", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[3,\n 2,\n 1,\n 2,\n 2,\n 1,\n 0,\n 2,\n 3,\n 3,\n 1,\n 3,\n 1,\n 2,\n 2,\n 3,\n 0,\n 1,\n 3,\n 1,\n 3,\n 2,\n 2,\n 1,\n 0,\n 3,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 3,\n 1,\n 2,\n 0,\n 0,\n 2,\n 0,\n 2,\n 3,\n 3,\n 1,\n 2,\n 1,\n 2,\n 3,\n 2,\n 1,\n 3,\n 1,\n 0,\n 3,\n 0,\n 1,\n 0,\n 3,\n 2,\n 2,\n 2,\n 3,\n 2]"}, "execution_count": 80}], "execution_count": 80}, {"source": "ctr_test_cv=0\nfor i in range(len(y_pred_test_cv)):\n    if y_pred_test_cv[i] == y_test_labels_cv[i]:\n        ctr_test_cv=ctr_test_cv+1\nres_test_cv = ctr_test_cv/len(y_pred_test_cv)*100\nprint(res_test_cv)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "83.87096774193549\n"}], "execution_count": 81}, {"source": "Accuracy testing of validation data set.", "cell_type": "markdown", "metadata": {}}, {"source": "#predictions_test\npredictions_val_cv = cv_model.predict(X_val)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 82}, {"source": "y_pred_val_cv =[]\nfor i in range(len(predictions_val_cv)):\n    y_pred_val_cv.append(np.argmax(predictions_val_cv[i]))\nprint(y_pred_val_cv)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2, 3, 1, 1, 3, 1, 3]\n"}], "execution_count": 83}, {"source": "y_val", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.]])"}, "execution_count": 84}], "execution_count": 84}, {"source": "y_val_labels_cv = [ np.where(r==1)[0][0] for r in y_val ]\ny_val_labels_cv", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]"}, "execution_count": 85}], "execution_count": 85}, {"source": "ctr_val_cv=0\nfor i in range(len(y_pred_val_cv)):\n    if y_pred_val_cv[i] == y_val_labels_cv[i]:\n        ctr_val_cv=ctr_val_cv+1\nres_val_cv = ctr_val_cv/len(y_pred_val_cv)*100\nprint(res_val_cv)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "83.33333333333334\n"}], "execution_count": 86}, {"source": "## 4.4 Confusion matrix", "cell_type": "markdown", "metadata": {}}, {"source": "Confusion matrix for test dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "# confusion matrix for test data\ny_actu_test_cv = y_test_labels_cv\ny_pred_test_cv = y_pred_test_cv\ncm_test_cv = ConfusionMatrix(actual_vector=y_actu_test_cv, predict_vector=y_pred_test_cv) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 87}, {"source": "cm_test_cv.classes", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[0, 1, 2, 3]"}, "execution_count": 88}], "execution_count": 88}, {"source": "cm_test_cv.table", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "{0: {0: 11, 1: 0, 2: 0, 3: 0},\n 1: {0: 0, 1: 15, 2: 0, 3: 2},\n 2: {0: 0, 1: 1, 2: 14, 3: 3},\n 3: {0: 0, 1: 3, 2: 1, 3: 12}}"}, "execution_count": 89}], "execution_count": 89}, {"source": "cm_test_cv.print_matrix()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Predict  0        1        2        3        \nActual\n0        11       0        0        0        \n\n1        0        15       0        2        \n\n2        0        1        14       3        \n\n3        0        3        1        12       \n\n\n"}], "execution_count": 90}, {"source": "Confusion matrix for validation dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "# confusion matrix for test data\ny_actu_val_cv = y_val_labels_cv\ny_pred_val_cv = y_pred_val_cv\ncm_val_cv = ConfusionMatrix(actual_vector=y_actu_val_cv, predict_vector=y_pred_val_cv)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 91}, {"source": "cm_val_cv.classes", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[0, 1, 2, 3]"}, "execution_count": 92}], "execution_count": 92}, {"source": "cm_val_cv.table", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "{0: {0: 6, 1: 0, 2: 0, 3: 0},\n 1: {0: 0, 1: 6, 2: 0, 3: 0},\n 2: {0: 0, 1: 0, 2: 5, 3: 1},\n 3: {0: 0, 1: 3, 2: 0, 3: 3}}"}, "execution_count": 93}], "execution_count": 93}, {"source": "#print(cm_val)\ncm_val_cv.print_matrix()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Predict 0       1       2       3       \nActual\n0       6       0       0       0       \n\n1       0       6       0       0       \n\n2       0       0       5       1       \n\n3       0       3       0       3       \n\n\n"}], "execution_count": 94}, {"source": "# 5. Persist the model\n\nIn this section, we will show how to use the watson-machine-learning-client package to store your ANN model in the WML repository.", "cell_type": "markdown", "metadata": {}}, {"source": "!rm -rf $PIP_BUILD/watson-machine-learning-client", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 95}, {"source": "!pip install watson-machine-learning-client", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Requirement already satisfied: watson-machine-learning-client in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (1.0.365)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (2.0.1)\nRequirement already satisfied: tabulate in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (0.8.2)\nRequirement already satisfied: tqdm in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (4.19.5)\nRequirement already satisfied: urllib3 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (1.22)\nRequirement already satisfied: lomond in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (0.1.13)\nRequirement already satisfied: certifi in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (2019.3.9)\nRequirement already satisfied: pandas in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (0.21.0)\nRequirement already satisfied: requests in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client) (2.18.4)\nRequirement already satisfied: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.0.1)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.0.1)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from lomond->watson-machine-learning-client) (1.11.0)\nRequirement already satisfied: python-dateutil>=2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client) (2.6.1)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client) (2018.3)\nRequirement already satisfied: numpy>=1.9.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client) (1.13.3)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client) (3.0.4)\nRequirement already satisfied: idna<2.7,>=2.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client) (2.6)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.9.3)\nRequirement already satisfied: docutils>=0.10 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.14)\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n"}], "execution_count": 96}, {"source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"}], "execution_count": 97}, {"source": "wml_credentials={\n    'url': 'https://us-south.ml.cloud.ibm.com',\n    'access_key': '1i_a51p0p4pg-wRnOy3XdLwHrxzURhXz2_dERELy_RR-',\n    'username': '68c5e0c2-16df-4265-9846-3c382fd66494',\n    'password': 'b696c9e3-d790-41c6-900d-580a64f9ccbb',\n    'instance_id': '985d7680-d220-4984-85e1-31cf24cd3369'\n}", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 98}, {"source": "client = WatsonMachineLearningAPIClient(wml_credentials)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 99}, {"source": "## 5.1 Save the ANN model in the WML Repository", "cell_type": "markdown", "metadata": {}}, {"source": "Save the model artifact as model for image recognition to WML instance.", "cell_type": "markdown", "metadata": {}}, {"source": "#### Step 1: Save your model to .h5 file.", "cell_type": "markdown", "metadata": {}}, {"source": "#ANN_model_result_path = \"/home/dsxuser/work/datasetWS_DvsEvsHvsM_512-512_git/class_4_ANN_model_DvsEvsHvsM_v1-1.h5\"\n#ANN_model.save(ANN_model_result_path)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 100}, {"source": "cv_model_result_path = \"/home/dsxuser/work/datasetWS_DvsEvsHvsM_512-512_git/class_4_ANN_cv_model_DvsEvsHvsM_v1.h5\"\ncv_model.save(cv_model_result_path)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 101}, {"source": "!ls", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "class_4_ANN_cv_model_DvsEvsHvsM_v1.h5\t       README.md\r\nclass_4_ANN_cv_model_DvsEvsHvsM_v1_weights.h5  test_set\r\nclass_4_ANN_model_DvsEvsHvsM_v1-1.h5\t       training_set\r\nclass_4_ANN_model_DvsEvsHvsM_v1-1_weights.h5   validation_set\r\n"}], "execution_count": 102}, {"source": "#### Step 2: compress .h5 file to tgz.", "cell_type": "markdown", "metadata": {}}, {"source": "#!tar -zcvf class_4_ANN_model_DvsEvsHvsM_v1-1.tgz class_4_ANN_model_DvsEvsHvsM_v1-1.h5", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 103}, {"source": "!tar -zcvf class_4_ANN_cv_model_DvsEvsHvsM_v1.tgz class_4_ANN_cv_model_DvsEvsHvsM_v1.h5", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "class_4_ANN_cv_model_DvsEvsHvsM_v1.h5\r\n"}], "execution_count": 104}, {"source": "#### Step 3: Important > For deploying a keras model, it is mandatory to pass the FRAMEWORK_LIBRARIES along with other metaprops", "cell_type": "markdown", "metadata": {}}, {"source": "metadata = {\n         client.repository.ModelMetaNames.NAME: 'ANN cv model for grape leaves disease classification v1-1',\n         client.repository.ModelMetaNames.FRAMEWORK_NAME: 'tensorflow',\n         client.repository.ModelMetaNames.FRAMEWORK_VERSION: '1.5',\n         client.repository.ModelMetaNames.RUNTIME_NAME: 'python',\n         client.repository.ModelMetaNames.RUNTIME_VERSION: '3.5',\n         client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [{'name':'keras', 'version': '2.1.3'}]\n}", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 105}, {"source": "#### Step 4: Store the model.", "cell_type": "markdown", "metadata": {}}, {"source": "published_model = client.repository.store_model(model='class_4_ANN_cv_model_DvsEvsHvsM_v1.tgz', meta_props=metadata)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 106}, {"source": "# Display a list of all the models.\nclient.repository.list_models()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "------------------------------------  ------------------------------------------------------------  ------------------------  -----------------\nGUID                                  NAME                                                          CREATED                   FRAMEWORK\nf79bb1c3-2ab2-46de-bf24-cf1cf74ccfd4  ANN cv model for grape leaves disease classification v1-1     2019-07-09T09:14:57.196Z  tensorflow-1.5\nf3c83ce3-f555-4de5-8faa-791443690bc5  KNN model for grape leaves disease classification             2019-07-07T19:32:03.713Z  scikit-learn-0.19\nfc015b39-38b7-4433-aa34-3e3dab3ffc9f  CNN model for grape leaves disease classification 128-128 v3  2019-07-06T16:19:53.753Z  tensorflow-1.5\nf3cd09ae-d0ba-4c31-b652-eed80f40a52c  XGBoost model for grape leaves disease classification         2019-06-30T13:55:22.022Z  scikit-learn-0.19\n24abf95f-9ef9-4bf4-af17-46c199f94828  CNN model for grape leaves disease classification v1          2019-06-30T12:28:01.218Z  tensorflow-1.5\n1e538c7a-8582-4a29-b90d-0ce9e029550b  Birdsongs_ML_model2                                           2019-05-08T19:40:02.886Z  wml-1.1\n9a7bb8a5-c303-49ca-9610-23764cdab2e3  BirdSongs_ML_models                                           2019-05-08T19:30:54.465Z  wml-1.1\n3fdfc4fc-5d62-436c-99fd-f779adad9c55  Cats_and_Dogs_ML_model                                        2019-05-08T09:30:56.333Z  wml-1.1\n------------------------------------  ------------------------------------------------------------  ------------------------  -----------------\n"}], "execution_count": 107}, {"source": "## 5.2 Deploy the model", "cell_type": "markdown", "metadata": {}}, {"source": "We need the model uid to create the deployment. You can extract the model uid from the saved model details.", "cell_type": "markdown", "metadata": {}}, {"source": "#### Step 5: Deploy the model.\u00b6", "cell_type": "markdown", "metadata": {}}, {"source": "# Extract the uid.\nmodel_uid = client.repository.get_model_uid(published_model)\nprint(model_uid)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "f79bb1c3-2ab2-46de-bf24-cf1cf74ccfd4\n"}], "execution_count": 108}, {"source": "We use this modul_uid in the next section to create the deployment.", "cell_type": "markdown", "metadata": {}}, {"source": "## 5.3 Create a model deployment", "cell_type": "markdown", "metadata": {}}, {"source": "Now, we can create a deployment, and classify grape leaves diseases.", "cell_type": "markdown", "metadata": {}}, {"source": "# Create the deployment.\ndeployment_details = client.deployments.create(model_uid, 'Predict grape leaves diseases - ANN cv model final v1-1')", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: 'f79bb1c3-2ab2-46de-bf24-cf1cf74ccfd4' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS.\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='f9653920-f751-4726-847f-161b2099473e'\n------------------------------------------------------------------------------------------------\n\n\n"}], "execution_count": 109}, {"source": "Get the list of all deployments.", "cell_type": "markdown", "metadata": {}}, {"source": "# List the deployments.\nclient.deployments.list()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "------------------------------------  ----------------------------------------------------------  ------  --------------  ------------------------  -----------------  -------------\nGUID                                  NAME                                                        TYPE    STATE           CREATED                   FRAMEWORK          ARTIFACT TYPE\nf9653920-f751-4726-847f-161b2099473e  Predict grape leaves diseases - ANN cv model final v1-1     online  DEPLOY_SUCCESS  2019-07-09T09:14:59.593Z  tensorflow-1.5     model\n1ad8a2be-e619-4e8b-9146-d5ed417786c3  Predict grape leaves diseases KNN                           online  DEPLOY_SUCCESS  2019-07-07T19:32:36.573Z  scikit-learn-0.19  model\nf42ade46-aa26-4266-9028-1a52b01375ac  Predict grape leaves diseases - CNN model final 128-128 v3  online  DEPLOY_SUCCESS  2019-07-06T16:20:02.679Z  tensorflow-1.5     model\n48e42119-6c64-419c-9ee9-274148b3a9da  Predict grape leaves diseases                               online  DEPLOY_SUCCESS  2019-06-30T13:55:24.366Z  scikit-learn-0.19  model\nc3374942-d0f1-477b-9cde-aff5055abab9  Predict grape leaves diseases - CNN model final v1          online  DEPLOY_SUCCESS  2019-06-30T12:28:48.611Z  tensorflow-1.5     model\n------------------------------------  ----------------------------------------------------------  ------  --------------  ------------------------  -----------------  -------------\n"}], "execution_count": 110}, {"source": "The Predict grape leaves diseases model has been successfully deployed.", "cell_type": "markdown", "metadata": {}}, {"source": "## 5.4 Check the score using the deployed model", "cell_type": "markdown", "metadata": {}}, {"source": "Now, extract the url endpoint, scoring_url, which will be used to send scoring requests.", "cell_type": "markdown", "metadata": {}}, {"source": "# Extract endpoint url and display it.\nscoring_url = client.deployments.get_scoring_url(deployment_details)\nprint(scoring_url)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/985d7680-d220-4984-85e1-31cf24cd3369/deployments/f9653920-f751-4726-847f-161b2099473e/online\n"}], "execution_count": 111}, {"source": "Prepare the scoring payload with the values to score.", "cell_type": "markdown", "metadata": {}}, {"source": "# Prepare scoring payload.\n#payload_scoring = {'values': [list(X_test[0]), list(X_test[1])]}\npayload_scoring = {'values': [list(X_test[0]), list(X_test[1]), list(X_test[2])]}\nprint(payload_scoring)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "{'values': [[-0.1276993015213313, -0.0031469636521972897, 0.5677342097607132, 0.74790690134456317, 0.50043575092803416, 0.487466539970492, 0.9067859767259967, 0.988204451225702, 0.21903114734620405, -0.25171461677973095, -0.56526926222936791, -0.71884999929735272, -0.71552505633604191, -0.57864825310058221, -0.42778895821592289, -0.45648772634197282, -0.28064719074293704, -0.26357539098775823, 1.2997121379053747, 0.37866180710121528, 0.28767201526467567, 0.1853435357974835, 0.25793354827906489, -0.057388445534996328, -0.8004809428041898, -0.84453365171239247, -0.89334063162467725, -0.84380264977434949, -0.80956313484930431, -0.68504553872143092, -0.090043846523672894, 0.46157122135938117, 3.393945866040097, 2.6733088749441065, 1.4776933017941523, 1.2548005734312744, 0.76274923847969245, 0.65331313602083496, 1.2875848101400589, 0.78925853379479771, -0.00021575504000085683, -0.59042276306666186, -0.86852627194989973, -1.0439062948661635, -0.90795111426895259, -0.6387508401599844, -0.58613157472884392, -0.37104894188330684, -0.4609167905119817, -0.24208393787763161, -0.23299322649279672, -0.46679136876848409, 0.015744712170158839, 0.59624123055014033, 0.8735791650863598, 0.27790308972554018, -1.0755873701357135, -0.9830898755392623, -0.71775166422221592, -0.58428243314068196, -0.36956841442191291, 0.41513211119511101, 0.85450268733303902, 0.62351293416343179, 0.16824787833543928, -0.25617957401501235, -0.80307579047798905, -0.85404035255529931, -0.78406794927776013, -0.64370300637703315, -0.5138730528411124, -0.58059043559825385, -0.55655079455415335, -0.63584954409508887, -0.61140784140415738, -0.66515339756471792, -0.63773672390020397, -0.64916399254948554, -0.63773047098681335, -0.62334721944537985, -0.59257088526629609, -0.47717112774115583, -0.20924371597332025, -0.35527935174715686, -0.12485353078030904, -0.019966687726496096, 0.40491304056883209, 2.3342273205490516, -0.25514078255407169, -0.43957769692998117], [-0.12482026272339584, -0.24685531607812808, -0.28991060166846178, 0.53361651418076683, 0.9445680232607121, 0.99630734645710528, 0.30894025213350418, -0.12033748646667361, -0.49290104983095295, -0.49848012717012674, -0.46807189127111481, -0.36011113688055141, -0.33311012395279016, -0.17836241633460762, 0.033287776424048787, 0.24714396372237957, 0.46555703571586526, 0.64892944606673075, 0.44231041342329552, 0.18805316536648259, -0.070171869412724699, -0.31488535871181106, -0.49250148673542005, -0.46132108871950117, -0.42037224785779498, -0.27814205898366257, -0.1434867335315651, -0.14432015079745564, -0.11503096660045749, -0.311519232568649, -0.090043846523672894, -0.23896963147642206, -0.5383450670679486, -0.88963251811907584, -0.8279826499947841, -0.78812690668850838, -0.29020147586775835, 0.19482913833509227, 0.61653932017953794, 0.32004068161606719, 0.052907733866566206, -0.39728555406937099, -0.62544237579319739, -0.76858879489556764, -0.79305282068837757, -0.74206228815402475, -0.41500274535531123, -0.1635177841757742, 0.06049125100501429, 0.39936612005926697, 0.61386837616470991, 0.85887649696445101, 1.0947764759169289, 0.91307911652365303, 0.59953528197233863, 0.22418190805223712, 0.057658532436402045, -0.24580817951622241, -0.3106337398133508, -0.44580570968990879, -0.23163607075667272, 0.26585457249111194, 0.51097713507910181, 0.0054599575695584964, -0.17471226149838565, -0.23913709475866229, 0.11772947577619253, 0.39285052414858834, 0.65878543720639915, 0.7147015398089781, 0.50520384021813891, 0.18695062234467633, -0.075057217617810479, -0.25771793860923459, -0.241544081644429, -0.22034430254780343, -0.2055613824415316, -0.26061296483767582, -0.2057880091664066, -0.23875948132837749, -0.25318124592246238, -0.28265257500292246, -0.28598730631475427, -0.3114558967337685, -0.31700180921481441, -0.38885459358890684, -0.34052787189575517, -0.29638200595341285, -0.41949072831929457, -0.44076959304952112], [-0.1276993015213313, -0.21312782087632515, -0.26678420686801929, -0.32628454226486531, -0.62589183558689332, -0.93568940257947786, -1.0384655289934799, -0.87585582205181023, -0.56718352168632102, -0.2927856302009661, 0.13128291676662596, 0.46389268290073093, 0.43406296956606172, 0.25728245253948706, -0.022696340267631725, -0.18509153622095376, 0.16533737886485958, 0.25263983245803773, -0.068776839010324956, -0.3137314356659055, -0.3223044870892593, -0.41331586772221712, 0.15815454303645807, 2.9068597118356867, 4.3838783618149, 2.0902650618305119, -0.056073989793182656, -0.29923347359561053, -0.3237833494886494, -0.50223086668259587, -0.085944934273696594, -0.22843518256159795, -0.34323509976241473, -0.26521382745343614, -0.0060592274842208253, -0.014471983452768457, 0.0026270658782627889, -0.19700859295886083, -0.43918304055460489, -0.48522373240450678, -0.38309960078145028, -0.23449014225594442, -0.018082900381494196, 0.1402219972048224, 0.0090550011008736445, -0.13389883813984599, -0.37816251125406458, -0.39866613728883099, -0.27779167145307421, 0.0026834006963819051, -0.16604049294936105, -0.52828911895008956, -0.59365870700873391, -0.53688342569010772, -0.49800195921971613, 0.48969201950876495, 6.7629319326007007, -0.56767702804279729, -0.67323527325061727, -0.58299427757369804, 0.15831211397039802, 0.31997023289680254, 0.21350479725470353, -0.30264581258781514, -0.63799947389140177, -0.89301980461725516, -0.91646089205526404, -0.75260540021690914, -0.63762555372183127, -0.56077779897085855, -0.48751761595164883, -0.45607408963656793, -0.4367895627502919, -0.425534270726876, -0.39011735996375418, -0.43864194790056482, -0.57295361142305445, -0.45505668260168103, -0.36978755349394071, -0.25276914041372073, -0.002328034233541778, 0.43502959430564941, 0.018035378499388233, -0.12758792243846515, -0.089636643736042784, -0.091180569167115921, 0.13069727634078743, 1.6126964979447476, 2.362029454398674, -0.44196148916906108]]}\n"}], "execution_count": 112}, {"source": "# Perform prediction and display the result.\nimport json\nresponse_scoring = client.deployments.score(scoring_url, payload_scoring)\nprint(json.dumps(response_scoring, indent=3))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "{\n   \"values\": [\n      [\n         [\n            8.673925577795671e-09,\n            0.0041386159136891365,\n            3.919957089237869e-05,\n            0.9958221912384033\n         ],\n         3,\n         [\n            8.673925577795671e-09,\n            0.0041386159136891365,\n            3.919957089237869e-05,\n            0.9958221912384033\n         ]\n      ],\n      [\n         [\n            4.509344307734864e-06,\n            2.78419497590221e-06,\n            0.9933103322982788,\n            0.006682374514639378\n         ],\n         2,\n         [\n            4.509344307734864e-06,\n            2.78419497590221e-06,\n            0.9933103322982788,\n            0.006682374514639378\n         ]\n      ],\n      [\n         [\n            0.000582920212764293,\n            0.09217908978462219,\n            0.0008912426419556141,\n            0.9063467383384705\n         ],\n         3,\n         [\n            0.000582920212764293,\n            0.09217908978462219,\n            0.0008912426419556141,\n            0.9063467383384705\n         ]\n      ]\n   ],\n   \"fields\": [\n      \"prediction\",\n      \"prediction_classes\",\n      \"probability\"\n   ]\n}\n"}], "execution_count": 113}, {"source": "Result of the classification: The selected grape leaves are classified as mite, healthy and mite.", "cell_type": "markdown", "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}